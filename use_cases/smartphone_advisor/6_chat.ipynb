{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smartphones and Watches advisor\n",
    "In this serie of notebooks we will:\n",
    "- Load text from a Youtube video playlist\n",
    "- Split loaded text into appropriate chunks\n",
    "- Create a vector store to load chunk embeddings\n",
    "- **Create a Question Answering chatbot**:\n",
    "\n",
    "    - with or without prompts engineering\n",
    "    - with different similarity measures\n",
    "    - **with** or without **chat memory**\n",
    "\n",
    "!['Data Connection'](../../images/les_numeriques_youtube/data_connection.png)\n",
    "\n",
    "\n",
    "# Create a Question Answering chatbot\n",
    "\n",
    "Create a Question Answering memory chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "# Env var\n",
    "import os \n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Langchain\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# SelfQuery Retriever\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "# Compressor\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# QA retriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Prompt template\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Conversational chain \n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env variable\n",
    "sys.path.append('../..')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.langchain.plus\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"[YOUR_API_KEY]\"\n",
    "# Go to https://smith.langchain.com/\n",
    "# Setting > Create API key > Copy and past it in your.env file \n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815\n"
     ]
    }
   ],
   "source": [
    "# Load vector db\n",
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLM\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load compression retriever\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt\n",
    "template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "\n",
    "Keep the answer as concise as possible. \n",
    "You can answer with bullet point as well.\n",
    "\n",
    "Always say \"Merci pour cette question!\" at the end of the answer. \n",
    "\n",
    "\n",
    "CONTEXT: {context}\n",
    "-------\n",
    "Human: {question}\n",
    "Assistant:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=compression_retriever,\n",
    "    #retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}, # Add a prompt\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florian.bastin/Documents/Code/Octo/GenAI/langchain_discovery/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "L'iPhone 14 est équipé du processeur Apple A15 Bionic, a un écran de 6,7 pouces, une batterie améliorée, des capteurs présents sur les iPhone 13 Pro et un module frontal entièrement revu. Merci pour cette question!\n"
     ]
    }
   ],
   "source": [
    "question = \"Quelles sont les caractéristiques de l'iPhone 14 ?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Je viens de te présenter l'iPhone 13 Product Red. Merci pour cette question!\n"
     ]
    }
   ],
   "source": [
    "question = 'Quel iPhone viens tu de me présenter cher LLM ?'\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational retrieval chain \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt\n",
    "template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "\n",
    "Keep the answer as concise as possible. \n",
    "You can answer with bullet point as well.\n",
    "\n",
    "Always say \"Merci pour cette question!\" at the end of the answer. \n",
    "\n",
    "\n",
    "CONTEXT: {context}\n",
    "-------\n",
    "HISTORY: \n",
    "{chat_history}\n",
    "Human: {question}\n",
    "Assistant:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\", \"chat_history\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Use the following pieces of context to answer the question at the end. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
      "\n",
      "Keep the answer as concise as possible. \n",
      "You can answer with bullet point as well.\n",
      "\n",
      "Always say \"Merci pour cette question!\" at the end of the answer. \n",
      "\n",
      "\n",
      "CONTEXT: Comme prévu lors de sa canote de rentrée, Apple a annoncé non pas un, non pas deux, non pas trois, mais bien quatre iPhones. Pas d'iPhone mini au programme, mais ça c'était prévu. A la place on se retrouve avec un iPhone 14, un iPhone 14+, un iPhone 14 Pro et un iPhone 14 Pro Max et je vous propose qu'on décortique tout ça maintenant. On va commencer avec les deux entrées de gamme qui sont les iPhone 14 et les iPhone 14+.\n",
      "\n",
      "Alors esthétiquement, il n'y a rien de nouveau par rapport aux iPhone 13 mini et aux iPhone 13 de l'année dernière. A l'intérieur, c'est quasiment la même chose, sauf que l'on retrouve la puce Apple A15 Bionic que l'on retrouvait dans les iPhone 13 Pro et 13 Pro Max en 2021. Du côté de l'iPhone 14, on garde le même gabarit qu'avec l'iPhone 13 et du côté de l'iPhone 14+, on prend le même gabarit qu'un iPhone 14 Pro Max. Effectivement, c'est le grand modèle de cette entrée de gamme cette année.\n",
      "\n",
      "On a donc un écran de 6,7 pouces, mais pour le reste, c'est exactement la même fiche technique qu'un iPhone 14. La batterie a été améliorée, mais ça c'est grâce à la nouvelle puce. En photo, très peu de changements, si ce n'est qu'on récupère les capteurs qui étaient présents sur les iPhone 13 Pro pour le principal et pour l'ultra grand-angle. Le module frontal a été entièrement revu.\n",
      "\n",
      "Et enfin, contrairement aux 14 Pro et 14 Pro Max, on n'a pas de nouveau design sur l'écran, ce qui fait qu'on garde encore l'encoche et qu'on n'a pas le droit au Dynamic Island, sur lequel je reviendrai tout de suite. On passe maintenant au plus gros du morceau, aux plus intéressants, qui sont les iPhone 14 et les iPhone 14 Pro Max. Alors, ils gardent le même design que l'année dernière, ils gardent la même taille d'écran que l'année dernière. On a donc 6,1 et 6,7 pouces.\n",
      "-------\n",
      "HISTORY: \n",
      "\n",
      "Human: Quelles sont les caractéristiques de l'iPhone 14 ?\n",
      "Assistant:\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"Quelles sont les caractéristiques de l'iPhone 14 ?\"\n",
    "result = qa_chain({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les caractéristiques de l'iPhone 14 sont: \n",
      "- Écran de 6,7 pouces \n",
      "- Puce Apple A15 Bionic \n",
      "- Batterie améliorée \n",
      "- Capteurs photo du iPhone 13 Pro pour le principal et l'ultra grand-angle \n",
      "- Module frontal entièrement revu \n",
      "- Encoche et pas de Dynamic Island. \n",
      "\n",
      "Merci pour cette question!\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Quelles sont les caractéristiques de l'iPhone 14 ?\n",
      "Assistant: Les caractéristiques de l'iPhone 14 sont: \n",
      "- Écran de 6,7 pouces \n",
      "- Puce Apple A15 Bionic \n",
      "- Batterie améliorée \n",
      "- Capteurs photo du iPhone 13 Pro pour le principal et l'ultra grand-angle \n",
      "- Module frontal entièrement revu \n",
      "- Encoche et pas de Dynamic Island. \n",
      "\n",
      "Merci pour cette question!\n",
      "Follow Up Input: Quel iPhone viens tu de me présenter?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Use the following pieces of context to answer the question at the end. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
      "\n",
      "Keep the answer as concise as possible. \n",
      "You can answer with bullet point as well.\n",
      "\n",
      "Always say \"Merci pour cette question!\" at the end of the answer. \n",
      "\n",
      "\n",
      "CONTEXT: Il y en a bien plus, mais on ne va pas vous faire la liste ici. Le mieux, c'est de regarder la vidéo qu'on avait faite lorsque nous avions testé les bêtas. Vous pouvez la retrouver juste ici. Alors au final, qu'est ce qu'on pense de ces iPhones ? Commençons du plus petit au plus grand. L'iPhone classique et l'iPhone 13 mini, ils sont très bons. Ils sont performants. Ils ont de très beaux écrans qui sont néanmoins assez peu originaux au regard de ce qui se faisait l'an dernier.\n",
      "\n",
      "Je sais que vous voulez savoir ce que vaut ce dernier iPhone. Eh bien, pour la faire court, c'est excellent. Et en même temps, on n'en attendait pas moins d'Apple. On est là face à un des meilleurs smartphones présents sur le marché. Mais ça, c'est vraiment pour résumer. Dans le détail, on peut parler de cet écran OLED qui est le plus lumineux que nous ayons pu voir sur un smartphone. Il peut monter jusqu'à 1955 nits, là où Apple en promet 2000.\n",
      "\n",
      "Moins discrète qu'une encoche, c'est certain, mais c'est un nouveau temps d'adaptation qu'il va falloir prendre. Allez, je sais que vous l'attendiez. Abordons enfin la partie que tout le monde attend en photo. Que vaut ce nouvel iPhone ? Alors déjà, on va commencer par saluer la performance délivrée par le nouveau capteur de 48 mégapixels. Franchement, ça faisait longtemps qu'on attendait et Apple parvient à proposer quelque chose de très propre.\n",
      "\n",
      "Puisque c'est Kevin qui est plutôt sur les smartphones IOS. Kevin règne sans partage sur IOS. C'est le moment où tu peux dénoncer, tu as la parole. Non pas du tout, ça me va très bien. Moi j'aime bien faire des mathématiques. Donc avec Xiaomi j'ai des 11, des 12, des 17. Ça me va. Si vous avez quelques questions. Sauf évidemment quelle Mi 11 je dois acheter. Parce que je pense que c'est impossible d'y répondre. Mais surtout tu as testé tellement de smartphones.\n",
      "-------\n",
      "HISTORY: \n",
      "\n",
      "Human: Quelles sont les caractéristiques de l'iPhone 14 ?\n",
      "Assistant: Les caractéristiques de l'iPhone 14 sont: \n",
      "- Écran de 6,7 pouces \n",
      "- Puce Apple A15 Bionic \n",
      "- Batterie améliorée \n",
      "- Capteurs photo du iPhone 13 Pro pour le principal et l'ultra grand-angle \n",
      "- Module frontal entièrement revu \n",
      "- Encoche et pas de Dynamic Island. \n",
      "\n",
      "Merci pour cette question!\n",
      "Human:  Quel est l'iPhone dont tu viens de me présenter les caractéristiques ?\n",
      "Assistant:\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"Quel iPhone viens tu de me présenter?\"\n",
    "result = qa_chain({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'iPhone dont je viens de vous présenter les caractéristiques est l'iPhone 14. \n",
      "\n",
      "Merci pour cette question!\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
